\chapter{Introduction}
\label{chap:Intro}
\textit{In this chapter the \CSP{} (\csp) is introduced as the main target problem. Since they are extremely complicated, they are tackled by meta-heuristic methods. However, this methods are not sufficient for some problem instances. The new era of parallelism has opened new ways to solve \csps{}. \posl{} is proposed as an alternative, a Parallel-Oriented Solver Language to build many different solvers working in parallel, that provides simple mechanisms to construct communication strategies with few effort. Finally, the structure of this document is presented.}
\vfill
\minitoc
\newpage

Combinatorial optimization is the act of obtaining the best result for a problem from a finite set of possibilities. These possibilities are the different combinations of values that the variables can take (configurations), taking into account their domains (integer values), and sometimes a given finite set of restrictions (constraints). These problems have several applications in many fields. In airlines, the crew scheduling is an example of \COP. It consists of covering flights of the company scheduled in a given time window, with minimum cost, making an efficient and realistic use of the available personal. The problem of task assignment for parallel programs, is one of the most important in parallelism, because it represents the core of a good program performance running in several machines \cite{Paschos2013}. %The design of telecommunication networks is an other example of these kind of problems, and it becomes more complicated in the same way as the development of the technology. 
\COPs{} are also present in electrical engineering, for example, when an efficient circuit layout design is needed \cite{Barahona1988}. 

In some cases, all feasible solutions, i.e., configurations fulfilling all constraints, are equally important, hence, the main goal is only to find  one of these solutions. This is the case of {\it Constraint Satisfaction Problems (CSP)}. In other words, a solution is an assignment of variables satisfying the constraint set. There exist many different techniques to solve such problems, mainly classified into two categories. In the first category are tree-search based algorithms, exploring the full search space. Two of the most important methods in this category are: \begin{inparaenum}[a)] \item The \textit{constraint propagation} method. It proceeds as follows: when a given variable is assigned a value, the algorithm recomputes the possible value sets and assigned values of all other (not yet assigned) variables. The process continues recursively until there are no more changes in the model. These way, an equivalent but smaller and easier to solve problem is obtained. \item The \textit{backtracking} method. It incrementally constructs candidates to the solutions, by assigning values to variables. Each time an assignment cannot possibly be completed to a valid solution, the previews assignation is discarded. \end{inparaenum} 

In practice, \CSPs{} are intractable. Their search space is huge enough to make tree-search based algorithms useless to solve them. In contrast, in the second category are the \textit{meta-heuristics} methods, algorithms that have been shown to be effective in the resolution of these kind of problems. They are an iterative generation process which guides algorithms by combining intelligently different mechanisms for exploring and exploiting the search space, in order to find efficiently near-optimal solutions \cite{Osman1996}. In this category, two groups of methods can be found \cite{Boussaid2013}: \begin{inparaenum}[a)] \item Single-solution based methods (also known as \textit{local search}). They start with an initial solution and move trying to improve it, inside the search space. \item Population-based methods. in these methods, a set of solutions is modified through operators (recombination, mutation, etc.). \end{inparaenum} Both are nature-inspired methods.

On the other hand, the development of computer architecture is leading us toward massively multi/many--core computers. These architectures unlock new algorithmic possibilities to tackle problems sequential algorithms cannot handle, reducing the search times.  However, \modified{this development must go hand by hand with the development of parallel algorithms.} At the time of writing a solution algorithm in parallel, some important decisions have to be taken. The way of organizing the search, either by dividing the search space, or by dividing the problem into smaller and easier to solve sub-problems, can provide an important speedup to the algorithm. Nevertheless, the multi-walk parallel scheme, where solvers work with the whole problem but searching in different zones of the search space, have shown very good results also. Other important decision is whether to use communication between process as a mechanism of cooperation. Theoretically, sharing information between solvers helps to the search process, but in practice, an equilibrium between the contribution of the communication and its inherent overheads is needed.

Many results can be showed in parallel computing. Adaptive Search~\cite{Diaz} is an efficient method reaching linear speed-ups on hundreds and even thousands of cores (depending of the problem), using an independent multi-walk local search parallel scheme. Munera et al~\cite{Munera} present another implementation of this algorithm using communication between search engines, showing the efficiency of cooperative multi-walks strategies. All these results use a multi-walk parallel approach and show the robustness and efficiency of this parallel scheme. Although, they all concluded there is room for improvements. 

With all these elements, the idea of obtaining a tool to rapidly prototyping solution and communication strategies emerges. In that sense, the \textbf{main goal} of this work is to provide a framework to build/use easily and rapidly:
\begin{enumerate}
\item \textit{Computation modules}: simple functions easily reusable, which can be used to built meta-heuristic-based algorithm by joining them.
\item \textit{Abstract solvers}: algorithms templates, which can be used to build many different solvers, instantiating different \oms.
\item Different \comstrs.
\end{enumerate} 

\section{Goals and contributions}

The \underline{first contribution} of this thesis is proposed: 
\begin{center}
\posl{} (pronounced "puzzle")\\
\textbf{Parallel-Oriented Solver Language}
\end{center}
It is a framework based on the creation/utilization of \textit{modules} interconnected through operators, to create local-search meta-heuristic-based solvers. These solvers work in parallel using the multi-walk parallel scheme, and they are connected to each other through communication operators, allowing information sharing. It is well-known software programming is a very time-consuming activity. This is even more the case while developing a parallel software, where debugging is an extremely difficult task. That is why \posl{} is based on re-usability to propose to \csp{} solver designers/programmers a parallel framework to quickly build parallel prototypes, speeding-up the design process.

\posl{} is a language designed to combine \ms{} available in the framework, or to create new ones. There exist two types of \ms{}: \oms{}, simple functions receiving an input, then executing an internal algorithm and returning an output, and \opchs{}, responsible for the information sharing.
The created/chosen \ms{} are joined through operators (the \posl's language) to create independent solvers. After that, created solvers can be connected each other using communication operators. This final entity is called a \soset. \posl{} also provides a framework specification to implement the benchmark (problems to solve), respecting some requirements.

%In this thesis we present \posl, a framework for easily building many and different cooperating solvers based on coupling four fundamental and independent components: \oms, \opchs, the \ass{} and \comstrs. Recently, the hybridization approach leads to very good results in constraint satisfaction. For that reason, since the solver's component can be combined, our framework is designed to execute in parallel sets of different solvers, with and without communication.

This framework was inspired by a similar idea proposed in \cite{Fukunaga2008} without communication, introducing an evolutionary approach that uses a simple composition operator to automatically discover new local search heuristics for SAT and to  visualize them as combinations of a set of building blocks. Renaud De Landtsheer et al. present in \cite{Landtsheer2015} a framework to facilitate the development of search procedures by using \textit{combinators} to design features commonly found in search procedures as standard bricks and joining them. This approach can speed-up the development and experimentation of search procedures when developing a specific solver based on local search. In \cite{Martin2016} is proposed an approach of using cooperating meta-heuristic-based local search processes, using an asynchronous message passing protocol. The cooperation is based on the general strategies of pattern matching and reinforcement learning. \posl{} uses the combination of both ideas, by combining features of the search process through provided operators, but it also provides an operator-based mechanism to connect solvers, creating \comstrs.

%In the last phase of the coding process with \posl{}, solvers can be connected each others, depending on the structure of their \opchs, and this way, they can share not only information, but also their behavior, by sharing their \oms. This approach makes the solvers able to evolve during the execution.

The \underline{second contribution} of the present work is a detailed study of the solution process of some \CSPs{} chosen as benchmarks, using \posl{}. In this study some different strategies are proposed, in order to show how the communication can play an important role in the solution of \csps{}.

A first study was made using the \sgp{}, in which a \textit{standard} communication strategy is used: the communication of the current configuration. This strategy shows to be effective, because it helps to preserve the equilibrium between exploration and exploitation, necessary in the efficient resolution of this problem.

With the \carrp{}, a similar study was performed, with the slightly difference that the configuration was transmitted in different places of the algorithm.

Another study was performed using the \nqp{}, in which it was observed that a standard communication strategy is not enough to improve the results without communication. However, with this benchmark a strategy of search-pace partitioning was implemented. This strategy was able to accelerate the beginning of the search, hence the final result in terms of runtime and iterations.

Finally, the \grp{} was used to study a different communication strategy, in which the current configuration is communicated, but in contrast to the previews strategies, this configuration is not used to be improved, but to be avoided. The principle is to communicate potential local minima to some solvers, and they will avoid them every time they perform a restart. 

In every case, it was possible to show the positive effect of the inter-processes communication. Despite intrinsic overheads, the solver cooperation scheme can help significantly in the search process, if it is studied and chosen correctly. For that reason this study has allowed the validation of the effectiveness of \posl{} to this purpose.

\section{Structure of the document}

Chapter~\ref{chap:art} presents an overview to the state of the art of \COPs{}. Its definition and the link with \CSPs{} (\csp) are presented, as well as the principal methods to solve them. This chapter is a \tet{travel} among basic techniques, like {\it Constraint Propagation}, {\it meta-- and hyper--heuristic methods}; advanced techniques, like {\it hybridization}, {\it parallel computing}, and {\it Solvers cooperation}; and {\i parameter setting techniques}.

In Chapter~\ref{chap:prior} prior works leading to \posl{} are presented. The problem subdivision approach was adopted to divide the domain of a given problem in parallel, in particular, to solve the \textit{K-Medoids Problem}. It contains also a performed study applying the {\sc ParamILS} tool to find the optimum parameter configuration to \textit{Adaptive Search} solver. {\sc ParamILS} (version 2.3) is a tool for parameter optimization for parametrized algorithms.

In Chapter~\ref{chap:posl} is presented formally \posl, the Parallel-Oriented Solver Language that is the heart of this thesis and its main contribution to the community. Its characteristics, main advantages, and a general procedure to be followed in order to use it to solve \CSPs{} is
presented.

Results for each study using \posl{} to build \comstrs{} to solve the proposed benchmarks are presented in Chapter~\ref{chap:expe}. In each section, a benchmark problem is defined, the used \soset{} for each communication strategy are presented, and results are analyzed (details of experiments can be found in Appendices). 

Finally, the main results of this thesis are summarized in Chapter~\ref{chap:conclusion}, where possible new lines of investigation are also discussed.